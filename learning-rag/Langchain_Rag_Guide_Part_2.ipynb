{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOMpjORgbeSaKvV61aFgPUu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/duyvm/funny_stuff_with_llm/blob/main/learning-rag/Langchain_Rag_Guide_Part_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install\n",
        "\n",
        "- Install required packages\n",
        "- Set environment variables\n",
        "- Load model and vector db"
      ],
      "metadata": {
        "id": "D62HrNJ8BXdF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "6ym6NvY0p5ek",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b62771b6-550b-4e07-d679-225f64892197"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m152.4/152.4 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m438.1/438.1 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.2/44.2 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.0/50.0 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.0/363.0 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.3/65.3 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m216.5/216.5 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "%pip install --quiet --upgrade langchain-text-splitters langchain-community langgraph langchain[openai] langchain-core beautifulsoup4"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "import os\n",
        "\n",
        "os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
        "os.environ[\"LANGSMITH_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
        "os.environ[\"LANGSMITH_PROJECT\"] = f\"langchain-learning-rag\"\n",
        "os.environ[\"LANGSMITH_API_KEY\"] = userdata.get('LANGSMITH_API_KEY')\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')"
      ],
      "metadata": {
        "id": "xmtEhKrEACgf"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preview\n",
        "\n",
        "- Guide: [Build a Retrieval Augmented Generation (RAG) App: Part 2](https://python.langchain.com/docs/tutorials/qa_chat_history/)\n",
        "\n",
        "- Extend application capabilities beyond document retrieval:\n",
        "\n",
        "  - Add `memory` of past questions and answers\n",
        "\n",
        "  - Incorporating this `memory` into thinkings for accuracy retrieved results\n",
        "\n",
        "  - Add `query analysis` (missing in part 1)\n",
        "\n",
        "\n",
        "- Follow the tutorial, two approaches:\n",
        "\n",
        "  - Chains (or AI worflow): application execute at most one retrieval step each query\n",
        "\n",
        "  - Agents: give the application discretion to execute multiple retrieval steps for finding the optimal answer"
      ],
      "metadata": {
        "id": "j60Ksa78BWHs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chat_models import init_chat_model\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "from langchain_core.vectorstores import InMemoryVectorStore\n",
        "\n",
        "llm = init_chat_model(\"gpt-4o-mini\", model_provider=\"openai\")\n",
        "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")\n",
        "vector_store = InMemoryVectorStore(embeddings)"
      ],
      "metadata": {
        "id": "ODab8Rm96Ozt"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Chains approach\n",
        "\n",
        "- Application execute at most one retrieval step each query"
      ],
      "metadata": {
        "id": "LQDIwj9Y6Vvu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import bs4\n",
        "from langchain import hub\n",
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "from langchain_core.documents import Document\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from langgraph.graph import START, StateGraph, MessagesState\n",
        "from typing_extensions import List, TypedDict\n",
        "\n",
        "# load and chunk the content of the blog\n",
        "blog_url = \"https://lilianweng.github.io/posts/2023-06-23-agent/\"\n",
        "\n",
        "loader = WebBaseLoader(\n",
        "    web_paths=(blog_url,),\n",
        "    bs_kwargs=dict(\n",
        "        parse_only=bs4.SoupStrainer(\n",
        "            class_=(\"post-content\", \"post-title\", \"post-header\")\n",
        "        )\n",
        "    )\n",
        ")\n",
        "\n",
        "docs = loader.load()"
      ],
      "metadata": {
        "id": "kNRkPSsFBCk6"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# split the documents\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
        "all_splits = text_splitter.split_documents(docs)"
      ],
      "metadata": {
        "id": "rwB3LH7pDcsk"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# index chunk and store in db\n",
        "_ = vector_store.add_documents(all_splits)"
      ],
      "metadata": {
        "id": "6sJNQwjtDdXW"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tool-calling for retrieval step\n",
        "\n",
        "- Instead of passing the whole user's question as query for searching relevant documents, we can leverage tool-calling for the retrieval step. With this approach, our query will be generated by the model. It is not only extract information from current user's question, but also gather information based on chat history for contextualization.\n",
        "\n",
        "- This is important in a conversational setting.\n",
        "\n",
        "- This allows the model to rewrite our queries into more effective search queries.\n",
        "\n",
        "- Furthermore, leveraging model in retrieval step can support direct reponse that is not involve a retrieval step"
      ],
      "metadata": {
        "id": "8zVYBfpUfmr8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.tools import tool\n",
        "\n",
        "# wrap our retrieve function with tool\n",
        "@tool(response_format=\"content_and_artifact\")\n",
        "def retrieve(query: str):\n",
        "    \"\"\"\n",
        "    Retrieve information related to input query\n",
        "    \"\"\"\n",
        "    retrieved_docs = vector_store.similarity_search(query, k=2)\n",
        "    serialized = \"\\n\\n\".join(\n",
        "        (f\"Source: {doc.metadata}\\n\" f\"Content: {doc.page_content}\")\n",
        "        for doc in retrieved_docs\n",
        "    )\n",
        "    return serialized, retrieved_docs"
      ],
      "metadata": {
        "id": "X1SJNbKnIBCz"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prepare function for Graph's Node\n",
        "\n",
        "Graph consists of three nodes:\n",
        "\n",
        "1. A node that receive user input, either responding directly or generating a query for next node\n",
        "\n",
        "2. A node for retriever tool that execute retrieval step\n",
        "\n",
        "3. A node that generates final response using retrieved information\n",
        "\n",
        "The output from a step is wrap to `ToolMessage`"
      ],
      "metadata": {
        "id": "I9vi33eeo9Ur"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.messages import SystemMessage\n",
        "from langgraph.prebuilt import ToolNode\n",
        "\n",
        "# 1st step\n",
        "def query_or_response(state: MessagesState):\n",
        "    \"\"\"\n",
        "    Generatate query for retrieval or response directly to user\n",
        "    \"\"\"\n",
        "    llm_with_tools = llm.bind_tools([retrieve])\n",
        "    response = llm_with_tools.invoke(state[\"messages\"])\n",
        "    # MessagesState will appends messages to state after each note execution\n",
        "    return {\"messages\": [response]}\n",
        "\n",
        "# 2nd step: retrieval\n",
        "tools = ToolNode([retrieve])\n",
        "\n",
        "# 3rd step: generate response to user's question based on retrieved context\n",
        "def generate(state: MessagesState):\n",
        "    \"\"\"\n",
        "    Generate response\n",
        "    \"\"\"\n",
        "    # get the most recent tool messages\n",
        "    recent_tool_messages = []\n",
        "    for message in reversed(state[\"messages\"]):\n",
        "        if message.type == \"tool\":\n",
        "            recent_tool_messages.append(message)\n",
        "        else:\n",
        "            break\n",
        "\n",
        "    # revese its order\n",
        "    tool_messages = recent_tool_messages[::-1]\n",
        "\n",
        "    # format into prompt\n",
        "    doc_content = \"\\n\\n\".join(doc.content for doc in tool_messages)\n",
        "    system_message = (\n",
        "        \"You are an assistant for question-answering tasks. \"\n",
        "        \"Use the following pieces of retrieved context to answer \"\n",
        "        \"the question. If you don't know the answer, just say that you \"\n",
        "        \"don't know, don't try to make up an answer. Use three sentences \"\n",
        "        \"maximum and keep the answer concise. \"\n",
        "        \"\\n\\n\"\n",
        "        f\"{doc_content}\"\n",
        "    )\n",
        "\n",
        "    conversation_messages = [\n",
        "        message\n",
        "        for message in state[\"messages\"]\n",
        "        if message.type in (\"human\", \"system\")\n",
        "        or (message.type == \"ai\" and not message.tool_calls)\n",
        "    ]\n",
        "\n",
        "    prompt = [SystemMessage(content=system_message)] + conversation_messages\n",
        "    response = llm.invoke(prompt)\n",
        "    return {\"messages\": [response]}"
      ],
      "metadata": {
        "id": "v9kZNOYhIrQO"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Build the Graph\n",
        "\n",
        "Build the graph by connecting all the steps into sequences and compile it"
      ],
      "metadata": {
        "id": "4kzRhLdNo8tc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.graph import END\n",
        "from langgraph.prebuilt import tools_condition\n",
        "\n",
        "graph_builder = StateGraph(MessagesState)\n",
        "\n",
        "graph_builder.add_node(query_or_response)\n",
        "graph_builder.add_node(tools)\n",
        "graph_builder.add_node(generate)\n",
        "\n",
        "graph_builder.set_entry_point(query_or_response.__name__)\n",
        "graph_builder.add_conditional_edges(\n",
        "    query_or_response.__name__,\n",
        "    tools_condition,\n",
        "    { END: END, tools.name: tools.name },\n",
        ")\n",
        "\n",
        "graph_builder.add_edge(tools.name, generate.__name__)\n",
        "graph_builder.add_edge(generate.__name__, END)\n",
        "\n",
        "graph = graph_builder.compile()"
      ],
      "metadata": {
        "id": "CmrJRRLPJwMJ"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# visualize the graph\n",
        "from IPython.display import Image, display\n",
        "\n",
        "display(Image(graph.get_graph().draw_mermaid_png()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "B5Xgc6BlJ6iU",
        "outputId": "b234a71d-6328-42d1-f0a8-7ce3668f8a68"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# testing with greeting message, not query\n",
        "for step in graph.stream(\n",
        "    {\"messages\": [{\"role\": \"user\", \"content\": \"Otsukareisama desu\"}]},\n",
        "    stream_mode=\"values\",\n",
        "):\n",
        "    step[\"messages\"][-1].pretty_print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1mgKH36UU5dc",
        "outputId": "7e4bb28a-7c52-4565-e623-bcf8d38fecd0"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "Otsukareisama desu\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "Otsukareisama desu (お疲れ様です) is a Japanese expression used to acknowledge someone's hard work or effort. It can be translated to \"Thank you for your hard work\" or \"Good job.\" It's commonly used in the workplace or after completing a task to show appreciation and respect. If you have any specific questions or need further information related to this phrase, feel free to ask!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ask about the content\n",
        "for step in graph.stream(\n",
        "    {\"messages\": [{\"role\": \"user\", \"content\": \"What is Task Decomposition?\"}]},\n",
        "    stream_mode=\"values\",\n",
        "):\n",
        "    step[\"messages\"][-1].pretty_print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ewLvA8JXVbct",
        "outputId": "5e4c4936-89d8-4aac-da30-14aa865504d4"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "What is Task Decomposition?\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Tool Calls:\n",
            "  retrieve (call_YltyPJ9e2zJ7oj35vlhu8dhV)\n",
            " Call ID: call_YltyPJ9e2zJ7oj35vlhu8dhV\n",
            "  Args:\n",
            "    query: Task Decomposition\n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "Name: retrieve\n",
            "\n",
            "Source: {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}\n",
            "Content: Task decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.\n",
            "Another quite distinct approach, LLM+P (Liu et al. 2023), involves relying on an external classical planner to do long-horizon planning. This approach utilizes the Planning Domain Definition Language (PDDL) as an intermediate interface to describe the planning problem. In this process, LLM (1) translates the problem into “Problem PDDL”, then (2) requests a classical planner to generate a PDDL plan based on an existing “Domain PDDL”, and finally (3) translates the PDDL plan back into natural language. Essentially, the planning step is outsourced to an external tool, assuming the availability of domain-specific PDDL and a suitable planner which is common in certain robotic setups but not in many other domains.\n",
            "Self-Reflection#\n",
            "\n",
            "Source: {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}\n",
            "Content: Component One: Planning#\n",
            "A complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\n",
            "Task Decomposition#\n",
            "Chain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.\n",
            "Tree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "Task decomposition is the process of breaking down a complicated task into smaller, more manageable steps or subgoals. This can be achieved using various methods, including prompting large language models (LLMs), task-specific instructions, or human inputs. Techniques like Chain of Thought (CoT) and Tree of Thoughts further enhance this process by structuring the reasoning and exploration of multiple possibilities.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# follow up question, no chat history\n",
        "for step in graph.stream(\n",
        "    {\"messages\": [{\"role\": \"user\", \"content\": \"Can you look up some common ways of doing it?\"}]},\n",
        "    stream_mode=\"values\",\n",
        "):\n",
        "    step[\"messages\"][-1].pretty_print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vQgG825WV511",
        "outputId": "755631d9-e928-4507-9888-117c52cff71b"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "Can you look up some common ways of doing it?\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Tool Calls:\n",
            "  retrieve (call_6ba1jv83ADZsNZOJ5Cq2XFVC)\n",
            " Call ID: call_6ba1jv83ADZsNZOJ5Cq2XFVC\n",
            "  Args:\n",
            "    query: common ways of doing it\n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "Name: retrieve\n",
            "\n",
            "Source: {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}\n",
            "Content: Task decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.\n",
            "Another quite distinct approach, LLM+P (Liu et al. 2023), involves relying on an external classical planner to do long-horizon planning. This approach utilizes the Planning Domain Definition Language (PDDL) as an intermediate interface to describe the planning problem. In this process, LLM (1) translates the problem into “Problem PDDL”, then (2) requests a classical planner to generate a PDDL plan based on an existing “Domain PDDL”, and finally (3) translates the PDDL plan back into natural language. Essentially, the planning step is outsourced to an external tool, assuming the availability of domain-specific PDDL and a suitable planner which is common in certain robotic setups but not in many other domains.\n",
            "Self-Reflection#\n",
            "\n",
            "Source: {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}\n",
            "Content: Resources:\n",
            "1. Internet access for searches and information gathering.\n",
            "2. Long Term memory management.\n",
            "3. GPT-3.5 powered Agents for delegation of simple tasks.\n",
            "4. File output.\n",
            "\n",
            "Performance Evaluation:\n",
            "1. Continuously review and analyze your actions to ensure you are performing to the best of your abilities.\n",
            "2. Constructively self-criticize your big-picture behavior constantly.\n",
            "3. Reflect on past decisions and strategies to refine your approach.\n",
            "4. Every command has a cost, so be smart and efficient. Aim to complete tasks in the least number of steps.\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "I don't know.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### With memory of history chat\n",
        "\n",
        "- Using in-memory"
      ],
      "metadata": {
        "id": "dIwA3sBKDkWY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.checkpoint.memory import MemorySaver\n",
        "\n",
        "memory = MemorySaver()\n",
        "graph = graph_builder.compile(checkpointer=memory)\n",
        "\n",
        "config = {\"configurable\": {\"thread_id\": \"duyvm456\"}}"
      ],
      "metadata": {
        "id": "br5nKokDWT7m"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# re-ask the questions\n",
        "for step in graph.stream(\n",
        "    {\"messages\": [{\"role\": \"user\", \"content\": \"What is Task Decomposition?\"}]},\n",
        "    stream_mode=\"values\",\n",
        "    config=config,\n",
        "):\n",
        "    step[\"messages\"][-1].pretty_print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ILHA3SwWVn1z",
        "outputId": "d4c331eb-38af-4856-a532-18c6888550df"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "What is Task Decomposition?\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Tool Calls:\n",
            "  retrieve (call_HarJbXJLD0vOdhxrmJFwC2ak)\n",
            " Call ID: call_HarJbXJLD0vOdhxrmJFwC2ak\n",
            "  Args:\n",
            "    query: Task Decomposition\n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "Name: retrieve\n",
            "\n",
            "Source: {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}\n",
            "Content: Task decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.\n",
            "Another quite distinct approach, LLM+P (Liu et al. 2023), involves relying on an external classical planner to do long-horizon planning. This approach utilizes the Planning Domain Definition Language (PDDL) as an intermediate interface to describe the planning problem. In this process, LLM (1) translates the problem into “Problem PDDL”, then (2) requests a classical planner to generate a PDDL plan based on an existing “Domain PDDL”, and finally (3) translates the PDDL plan back into natural language. Essentially, the planning step is outsourced to an external tool, assuming the availability of domain-specific PDDL and a suitable planner which is common in certain robotic setups but not in many other domains.\n",
            "Self-Reflection#\n",
            "\n",
            "Source: {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}\n",
            "Content: Component One: Planning#\n",
            "A complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\n",
            "Task Decomposition#\n",
            "Chain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.\n",
            "Tree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "Task decomposition is the process of breaking down a complicated task into smaller, manageable steps or subgoals. This can be accomplished using various methods, including simple prompting, task-specific instructions, or human input. Techniques like chain of thought (CoT) and tree of thoughts help enhance model performance by allowing for a structured approach to complex tasks.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for step in graph.stream(\n",
        "    {\"messages\": [{\"role\": \"user\", \"content\": \"Can you look up some common ways of doing it?\"}]},\n",
        "    stream_mode=\"values\",\n",
        "    config=config,\n",
        "):\n",
        "    step[\"messages\"][-1].pretty_print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nbtUBs9ZKJyY",
        "outputId": "effbf23f-7f37-465e-8dd8-35831fc5a75a"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "Can you look up some common ways of doing it?\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Tool Calls:\n",
            "  retrieve (call_4ULyFBC8mCVEuN5v2f4qPlgy)\n",
            " Call ID: call_4ULyFBC8mCVEuN5v2f4qPlgy\n",
            "  Args:\n",
            "    query: common methods of task decomposition\n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "Name: retrieve\n",
            "\n",
            "Source: {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}\n",
            "Content: Task decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.\n",
            "Another quite distinct approach, LLM+P (Liu et al. 2023), involves relying on an external classical planner to do long-horizon planning. This approach utilizes the Planning Domain Definition Language (PDDL) as an intermediate interface to describe the planning problem. In this process, LLM (1) translates the problem into “Problem PDDL”, then (2) requests a classical planner to generate a PDDL plan based on an existing “Domain PDDL”, and finally (3) translates the PDDL plan back into natural language. Essentially, the planning step is outsourced to an external tool, assuming the availability of domain-specific PDDL and a suitable planner which is common in certain robotic setups but not in many other domains.\n",
            "Self-Reflection#\n",
            "\n",
            "Source: {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}\n",
            "Content: Component One: Planning#\n",
            "A complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\n",
            "Task Decomposition#\n",
            "Chain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.\n",
            "Tree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "Common ways of task decomposition include: \n",
            "\n",
            "1. Simple prompting, such as asking for steps or subgoals related to a task. \n",
            "2. Task-specific instructions tailored to the nature of the task, like requesting a story outline for writing. \n",
            "3. Techniques like chain of thought (CoT) and tree of thoughts, which provide structured reasoning and exploration of multiple possibilities for each step.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Agent approach\n",
        "\n",
        "- Leverage reasoning capabilites of LLMs to make decisions during execution\n",
        "\n",
        "- No need for fixed path\n",
        "\n",
        "- Offload the discretion over the retrieval process"
      ],
      "metadata": {
        "id": "84B2ROjtGxXi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.prebuilt import create_react_agent\n",
        "\n",
        "agent_executor = create_react_agent(llm, [retrieve], checkpointer=memory)"
      ],
      "metadata": {
        "id": "ESJt5s0tKNKl"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instead of calling on the fixing path til final `generate` step at the end of the run. Here the agent continue calling the tools to retreive more information until it decides to answer the question"
      ],
      "metadata": {
        "id": "URQdsLbBH--J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "display(Image(agent_executor.get_graph().draw_mermaid_png()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        },
        "id": "Cy7AzhTWKZyh",
        "outputId": "7ea3fcb6-837e-4232-9b9a-97917f3ba7ca"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "config = {\"configurable\": {\"thread_id\": \"agent123\"}}\n",
        "\n",
        "input_message = (\n",
        "    \"What is the standard method for Task Decomposition?\\n\\n\"\n",
        "    \"Once you get the answer, look up common extensions of that method\"\n",
        ")\n",
        "\n",
        "for event in agent_executor.stream(\n",
        "    {\"messages\": [{\"role\": \"user\", \"content\": input_message}]},\n",
        "    stream_mode=\"values\",\n",
        "    config=config,\n",
        "):\n",
        "    event[\"messages\"][-1].pretty_print()"
      ],
      "metadata": {
        "id": "avA5mdJ6MFJG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c62523f-4187-4f59-f454-4a8824484c45"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "What is the standard method for Task Decomposition?\n",
            "\n",
            "Once you get the answer, look up common extensions of that method\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Tool Calls:\n",
            "  retrieve (call_MSOPWVP3bl9BUHzQiOAIxNJL)\n",
            " Call ID: call_MSOPWVP3bl9BUHzQiOAIxNJL\n",
            "  Args:\n",
            "    query: standard method for Task Decomposition\n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "Name: retrieve\n",
            "\n",
            "Source: {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}\n",
            "Content: Task decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.\n",
            "Another quite distinct approach, LLM+P (Liu et al. 2023), involves relying on an external classical planner to do long-horizon planning. This approach utilizes the Planning Domain Definition Language (PDDL) as an intermediate interface to describe the planning problem. In this process, LLM (1) translates the problem into “Problem PDDL”, then (2) requests a classical planner to generate a PDDL plan based on an existing “Domain PDDL”, and finally (3) translates the PDDL plan back into natural language. Essentially, the planning step is outsourced to an external tool, assuming the availability of domain-specific PDDL and a suitable planner which is common in certain robotic setups but not in many other domains.\n",
            "Self-Reflection#\n",
            "\n",
            "Source: {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}\n",
            "Content: Component One: Planning#\n",
            "A complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\n",
            "Task Decomposition#\n",
            "Chain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.\n",
            "Tree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Tool Calls:\n",
            "  retrieve (call_aDBXUSLV5DaYv4cFxIUMtSwQ)\n",
            " Call ID: call_aDBXUSLV5DaYv4cFxIUMtSwQ\n",
            "  Args:\n",
            "    query: common extensions of Task Decomposition methods\n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "Name: retrieve\n",
            "\n",
            "Source: {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}\n",
            "Content: Task decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.\n",
            "Another quite distinct approach, LLM+P (Liu et al. 2023), involves relying on an external classical planner to do long-horizon planning. This approach utilizes the Planning Domain Definition Language (PDDL) as an intermediate interface to describe the planning problem. In this process, LLM (1) translates the problem into “Problem PDDL”, then (2) requests a classical planner to generate a PDDL plan based on an existing “Domain PDDL”, and finally (3) translates the PDDL plan back into natural language. Essentially, the planning step is outsourced to an external tool, assuming the availability of domain-specific PDDL and a suitable planner which is common in certain robotic setups but not in many other domains.\n",
            "Self-Reflection#\n",
            "\n",
            "Source: {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}\n",
            "Content: Component One: Planning#\n",
            "A complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\n",
            "Task Decomposition#\n",
            "Chain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.\n",
            "Tree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "### Standard Method for Task Decomposition\n",
            "\n",
            "The standard methods for task decomposition involve several approaches, especially when dealing with large language models (LLMs):\n",
            "\n",
            "1. **Simple Prompting**: Use prompts such as \"Steps for XYZ.\\n1.\" or \"What are the subgoals for achieving XYZ?\" to guide the decomposition process.\n",
            "\n",
            "2. **Task-Specific Instructions**: Engage in task-specific instructions like \"Write a story outline.\" which help tailor the decomposition to a particular context.\n",
            "\n",
            "3. **Human Inputs**: Incorporate human insights and expertise to articulate subgoals and steps.\n",
            "\n",
            "4. **Long-Horizon Planning with LLM+P**: This method involves utilizing an external classical planner in conjunction with LLMs. It employs the Planning Domain Definition Language (PDDL) as a medium to describe the planning problem and translates this back and forth between natural language and PDDL.\n",
            "\n",
            "5. **Chain of Thought (CoT)**: A prompting technique that instructs models to \"think step by step.\" This helps to break down challenging tasks into manageable components and provides insights into the model's reasoning process.\n",
            "\n",
            "### Common Extensions of Task Decomposition\n",
            "\n",
            "- **Tree of Thoughts (ToT)**: An extension of the Chain of Thought method that broadens the reasoning possibilities at each stage. The task is decomposed into multiple thought steps, and for each step, various thoughts are generated, forming a tree structure. This method allows for either breadth-first search (BFS) or depth-first search (DFS) strategies to explore potential solutions.\n",
            "\n",
            "Overall, these approaches and extensions emphasize the importance of systematic breakdowns of tasks, leveraging both LLM capabilities and structured methodologies to achieve effective task planning and execution.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "z6piaZyTQSCi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}