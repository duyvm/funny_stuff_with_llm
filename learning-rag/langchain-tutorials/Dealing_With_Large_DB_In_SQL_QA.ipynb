{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPtvD5J1LEax9UqQzb49gWv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/duyvm/funny_stuff_with_llm/blob/main/learning-rag/Langchain_dealing_with_large_db_in_SQL_qa.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ym6NvY0p5ek"
      },
      "outputs": [],
      "source": [
        "%pip install --quiet --upgrade langchain-chroma langchain[openai] langchain langchain-community langgraph langchain-core langchain-text-splitters> /dev/null"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "import os\n",
        "\n",
        "os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
        "os.environ[\"LANGSMITH_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
        "os.environ[\"LANGSMITH_PROJECT\"] = f\"langchain-learning-rag\"\n",
        "os.environ[\"LANGSMITH_API_KEY\"] = userdata.get('LANGSMITH_API_KEY')\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')"
      ],
      "metadata": {
        "id": "xmtEhKrEACgf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Overview\n",
        "\n",
        "Guide: [How to deal with large databases when doing SQL question-answering](https://python.langchain.com/docs/how_to/sql_large_db/)\n",
        "\n",
        "## Objectives\n",
        "\n",
        "- It is wasted to include full db schema/tables/columns/row samples in every llm calls.\n",
        "\n",
        "- Need to find a dynamically identify/fetch and feed only a subset of tables/columns/row samples that relevant to the query in llm calls\n",
        "\n",
        "- Nowaday, the token size of llm is large so we can fit large context in prompt. But there is study stated that large context often lead to model reasoning degradation and poor performance.\n",
        "  - [Here](https://community.openai.com/t/reasoning-degradation-in-llms-with-long-context-windows-new-benchmarks/906891)\n",
        "\n",
        "  - [Here](https://osf.io/cf8v2)\n",
        "\n",
        "  - [And here](https://arxiv.org/html/2410.18745v1)"
      ],
      "metadata": {
        "id": "j60Ksa78BWHs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load data\n",
        "\n",
        "Load the Chinook db sql file and build the db"
      ],
      "metadata": {
        "id": "F7MiQWGzCE4W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt-get install sqlite3\n",
        "!curl -s https://raw.githubusercontent.com/duyvm/funny_stuff_with_llm/refs/heads/main/learning-rag/db/Chinook_Sqlite.sql | sqlite3 Chinook.db"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U17avUfoc_wh",
        "outputId": "60bba6e8-4504-4011-8aba-726d57271411"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "Suggested packages:\n",
            "  sqlite3-doc\n",
            "The following NEW packages will be installed:\n",
            "  sqlite3\n",
            "0 upgraded, 1 newly installed, 0 to remove and 35 not upgraded.\n",
            "Need to get 769 kB of archives.\n",
            "After this operation, 1,873 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 sqlite3 amd64 3.37.2-2ubuntu0.4 [769 kB]\n",
            "Fetched 769 kB in 4s (214 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 1.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package sqlite3.\n",
            "(Reading database ... 126281 files and directories currently installed.)\n",
            "Preparing to unpack .../sqlite3_3.37.2-2ubuntu0.4_amd64.deb ...\n",
            "Unpacking sqlite3 (3.37.2-2ubuntu0.4) ...\n",
            "Setting up sqlite3 (3.37.2-2ubuntu0.4) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.utilities import SQLDatabase\n",
        "\n",
        "db = SQLDatabase.from_uri(\"sqlite:///Chinook.db\", sample_rows_in_table_info=3)\n",
        "print(f\"dialect: {db.dialect}\")\n",
        "print(f\"table_names: {db.get_usable_table_names()}\")\n",
        "print(f\"Test 'SELECT * FROM Artist LIMIT 10;': {db.run('SELECT * FROM Artist LIMIT 10;')}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IQp8zoPMwQkx",
        "outputId": "f85eed16-1f97-4e14-bc9f-9e6c19429c8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dialect: sqlite\n",
            "table_names: ['Album', 'Artist', 'Customer', 'Employee', 'Genre', 'Invoice', 'InvoiceLine', 'MediaType', 'Playlist', 'PlaylistTrack', 'Track']\n",
            "Test 'SELECT * FROM Artist LIMIT 10;': [(1, 'AC/DC'), (2, 'Accept'), (3, 'Aerosmith'), (4, 'Alanis Morissette'), (5, 'Alice In Chains'), (6, 'Ant√¥nio Carlos Jobim'), (7, 'Apocalyptica'), (8, 'Audioslave'), (9, 'BackBeat'), (10, 'Billy Cobham')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chat_models import init_chat_model\n",
        "\n",
        "llm = init_chat_model(\"openai:gpt-4o-mini\")"
      ],
      "metadata": {
        "id": "yw6PKWu9DS3E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Using only relevant tables\n",
        "\n",
        "1. LLM call to get relevant table names (work best with table names + description + column names)\n",
        "\n",
        "2. LLM cal to generate query with provided relevant table schema"
      ],
      "metadata": {
        "id": "rLTnnFWXcK_l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.output_parsers.openai_tools import PydanticToolsParser\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from pydantic import BaseModel, Field\n",
        "\n",
        "class Table(BaseModel):\n",
        "    \"\"\"Table in SQL database\"\"\"\n",
        "    name: str = Field(description=\"Name of table in SQL database.\")\n",
        "\n",
        "table_names = \"\\n\".join(db.get_usable_table_names())\n",
        "\n",
        "print(table_names)"
      ],
      "metadata": {
        "id": "ExY7ibze_4qE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8dc99c50-ceb6-4ef6-e0b5-166c9b670c9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Album\n",
            "Artist\n",
            "Customer\n",
            "Employee\n",
            "Genre\n",
            "Invoice\n",
            "InvoiceLine\n",
            "MediaType\n",
            "Playlist\n",
            "PlaylistTrack\n",
            "Track\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "system_prompt = f\"\"\"\n",
        "Return the names of ALL the SQL tables that MIGHT be relevant to answer the question.\n",
        "The tables are:\n",
        "\n",
        "{table_names}\n",
        "\n",
        "Remember to include ALL POTENTIALLY RELEVANT tables, even if you are not sure that they are needed.\n",
        "\"\"\"\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [(\"system\", system_prompt), (\"human\", \"{input}\")]\n",
        ")\n",
        "\n",
        "# bind tools to llm\n",
        "llm_with_tool = llm.bind_tools([Table])\n",
        "output_parser = PydanticToolsParser(tools=[Table])\n",
        "\n",
        "chain = prompt | llm_with_tool | output_parser"
      ],
      "metadata": {
        "id": "e-FqBY4b4V2d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain.invoke(\"What are all the genres of Alanis Morissette songs?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KJ5OfONX4faf",
        "outputId": "a139c705-d514-4393-ce59-93f5d17865e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Table(name='Artist'),\n",
              " Table(name='Album'),\n",
              " Table(name='Genre'),\n",
              " Table(name='Track')]"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "After dynamically got the relevant tables, we add query synthesis step"
      ],
      "metadata": {
        "id": "a02fw-gQ8RbE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from operator import itemgetter\n",
        "from langchain.chains import create_sql_query_chain\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "\n",
        "query_chain = create_sql_query_chain(llm, db)\n",
        "\n",
        "table_chain = {\"input\": itemgetter(\"question\")} | chain | (lambda x: [ table.name for table in x])\n",
        "\n",
        "full_chain = RunnablePassthrough.assign(\n",
        "    table_names_to_use=table_chain\n",
        ") | query_chain | (lambda x: x.split(\"SQLQuery: \")[-1])"
      ],
      "metadata": {
        "id": "21svXIE06mxp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = full_chain.invoke(\n",
        "    {\"question\": \"What are all the genres of Alanis Morissette songs?\"}\n",
        ")\n",
        "print(query)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aDU0YVJu8eui",
        "outputId": "4dbe5f60-8f46-4d74-a8b6-2c819c905d3f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "```sql\n",
            "SELECT DISTINCT \"Genre\".\"Name\" \n",
            "FROM \"Track\" \n",
            "JOIN \"Album\" ON \"Track\".\"AlbumId\" = \"Album\".\"AlbumId\" \n",
            "JOIN \"Artist\" ON \"Album\".\"ArtistId\" = \"Artist\".\"ArtistId\" \n",
            "JOIN \"Genre\" ON \"Track\".\"GenreId\" = \"Genre\".\"GenreId\" \n",
            "WHERE \"Artist\".\"Name\" = 'Alanis Morissette' \n",
            "LIMIT 5;\n",
            "```\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## High-cardinality columns\n",
        "\n",
        "- High-cardinality columns often store Proper Noun (name, address)\n",
        "\n",
        "- To efficiently query data from these columns, we must check spelling of input Proper Noun before generating query\n",
        "\n",
        "- Naive strategy: create a vector store with all the distinct proper nouns that exist in the database -> query that vector store each user input and inject the most relevant proper nouns into the prompt."
      ],
      "metadata": {
        "id": "oH9dIDfKcC0c"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xMqECo1saguR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}