{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP57np2vzhjEU2kaANEvhQq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/duyvm/funny_stuff_with_llm/blob/main/learning-rag%5CLangchain_Rag_Guide_Part_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install\n",
        "\n",
        "- Install required packages\n",
        "- Set environment variables\n",
        "- Load model and vector db"
      ],
      "metadata": {
        "id": "D62HrNJ8BXdF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ym6NvY0p5ek"
      },
      "outputs": [],
      "source": [
        "%pip install --quiet --upgrade langchain-text-splitters langchain-community langgraph langchain[openai] langchain-core"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "import os\n",
        "\n",
        "os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
        "os.environ[\"LANGSMITH_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
        "os.environ[\"LANGSMITH_PROJECT\"] = f\"langchain-learning-rag\"\n",
        "os.environ[\"LANGSMITH_API_KEY\"] = userdata.get('LANGSMITH_API_KEY')\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')"
      ],
      "metadata": {
        "id": "xmtEhKrEACgf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chat_models import init_chat_model\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "\n",
        "llm = init_chat_model(\"gpt-4o-mini\", model_provider=\"openai\")\n",
        "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")"
      ],
      "metadata": {
        "id": "eWCkYZ34AuoI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.vectorstores import InMemoryVectorStore\n",
        "\n",
        "vector_store = InMemoryVectorStore(embeddings)"
      ],
      "metadata": {
        "id": "a2YVj2HDA2h-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preview\n",
        "\n",
        "- Guide: [Build a Retrieval Augmented Generation (RAG) App: Part 1](https://python.langchain.com/docs/tutorials/rag/)\n",
        "\n",
        "- Build an app that answers questions about the [LLM Powered Autonomous Agents](https://lilianweng.github.io/posts/2023-06-23-agent/) blog post by Lilian Weng\n",
        ". Allows us to ask questions about the contents of the post.\n",
        "\n",
        "- Create a simple indexing pipeline and RAG chain\n",
        "\n",
        "- Test around with another site, variants of question, multi languages"
      ],
      "metadata": {
        "id": "j60Ksa78BWHs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import bs4\n",
        "from langchain import hub\n",
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "from langchain_core.documents import Document\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from langgraph.graph import START, StateGraph\n",
        "from typing_extensions import List, TypedDict\n",
        "\n",
        "# load and chunk the content of the blog\n",
        "blog_url = \"https://lilianweng.github.io/posts/2023-06-23-agent/\"\n",
        "\n",
        "loader = WebBaseLoader(\n",
        "    web_paths=(blog_url,),\n",
        "    bs_kwargs=dict(\n",
        "        parse_only=bs4.SoupStrainer(\n",
        "            class_=(\"post-content\", \"post-title\", \"post-header\")\n",
        "        )\n",
        "    )\n",
        ")\n",
        "\n",
        "doc = loader.load()"
      ],
      "metadata": {
        "id": "kNRkPSsFBCk6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# split the documents\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
        "all_splits = text_splitter.split_documents(doc)"
      ],
      "metadata": {
        "id": "rwB3LH7pDcsk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# testing some facts\n",
        "fabricated_fact = \"Vo Minh Duy is a genius Vietnamese. He won 3 noble prizes in a row in Computer Science major. He graduated in Havard and now working in Marvel alliance. He is Iron Man's bff\"\n",
        "fabricated_doc = Document(page_content=fabricated_fact)\n",
        "all_splits.append(fabricated_doc)"
      ],
      "metadata": {
        "id": "XN2vD0YxJDHG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# index chunk and store in db\n",
        "_ = vector_store.add_documents(all_splits)"
      ],
      "metadata": {
        "id": "6sJNQwjtDdXW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = hub.pull(\"rlm/rag-prompt\")"
      ],
      "metadata": {
        "id": "GLfMKyD-GEN_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2nRGTJuqGOJS",
        "outputId": "9288ef81-82e8-4ba1-87ff-e020321f1a6c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ChatPromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, metadata={'lc_hub_owner': 'rlm', 'lc_hub_repo': 'rag-prompt', 'lc_hub_commit_hash': '50442af133e61576e74536c6556cefe1fac147cad032f4377b60c436e6cdcb6e'}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template=\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\\nQuestion: {question} \\nContext: {context} \\nAnswer:\"), additional_kwargs={})])"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# define state of langgraph\n",
        "class State(TypedDict):\n",
        "    question: str\n",
        "    context: List[Document]\n",
        "    answer: str"
      ],
      "metadata": {
        "id": "bbvSfqzuGO8t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define retrieva; step in graph\n",
        "# the actual function that will call to retrieve documents in vector db\n",
        "def retrieve(state: State) -> dict:\n",
        "    retrieved_docs = vector_store.similarity_search(state[\"question\"])\n",
        "    return {\"context\": retrieved_docs}"
      ],
      "metadata": {
        "id": "J0ciGIZrGsHZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define generation step\n",
        "def generate(state: State) -> dict:\n",
        "    doc_content = \"\\n\\n\".join([doc.page_content for doc in state[\"context\"]])\n",
        "    prompt_with_context = prompt.invoke(input={\"context\": doc_content, \"question\": state[\"question\"]})\n",
        "    answer = llm.invoke(prompt_with_context)\n",
        "    return {\"answer\": answer.content}"
      ],
      "metadata": {
        "id": "0cQN-acYHLO2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# compile the graph and test\n",
        "graph_builder = StateGraph(State).add_sequence([(\"1st\", retrieve), (\"2nd\", generate)])\n",
        "graph_builder.add_edge(START, \"1st\")\n",
        "graph = graph_builder.compile()"
      ],
      "metadata": {
        "id": "osQRpZR-H-Yx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = graph.invoke({\"question\": \"What is Task Decomposition?\"})\n",
        "print(response[\"answer\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X1SJNbKnIBCz",
        "outputId": "f5e5f0fb-1fd3-414c-c036-80f6aa1211ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Task decomposition is the process of breaking down a complicated task into smaller, manageable steps or subgoals. This can be achieved through various methods, including prompting language models, using task-specific instructions, or incorporating human inputs. Advanced techniques like Chain of Thought (CoT) and Tree of Thoughts further enhance this process by allowing iterative reasoning and exploration of multiple approaches.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = graph.invoke({\"question\": \"Who is Vo Minh Duy?\"})\n",
        "print(response[\"answer\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v9kZNOYhIrQO",
        "outputId": "6ffed3f6-193b-45ba-f002-0080b4646d76"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vo Minh Duy is a Vietnamese genius who has won three Nobel Prizes in Computer Science. He graduated from Harvard and currently works with Marvel Alliance, where he is a close friend of Iron Man.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = graph.invoke({\"question\": \"Any Vietnamese in the document?\"})\n",
        "print(response[\"answer\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CmrJRRLPJwMJ",
        "outputId": "a672e38b-abc1-454d-d061-1ebee1bade6b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Yes, Vo Minh Duy is mentioned as a Vietnamese individual. He is described as a genius who won three Nobel Prizes in Computer Science.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# some information not in our data store\n",
        "response = graph.invoke({\"question\": \"Who is Madam Luck?\"})\n",
        "print(response[\"answer\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JuzOTZwTJ3qS",
        "outputId": "82de5183-fd2c-4c26-923a-b7d19650f7b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I don't know.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = graph.invoke({\"question\": \"Tell me the greatness of Vo Minh Duy?\"})\n",
        "print(response[\"answer\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B5Xgc6BlJ6iU",
        "outputId": "9e6f73e5-0573-472f-a51f-8aa71ad2162a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vo Minh Duy is recognized as a genius Vietnamese who achieved the remarkable feat of winning three Nobel Prizes in Computer Science. He graduated from Harvard University and currently works for Marvel Alliance, where he is noted as Iron Man's best friend. His achievements highlight his exceptional intellect and contributions to the field.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = graph.invoke({\"question\": \"Cho tÃ´i thÃ´ng tin vá» Ã´ng VÃµ\"})\n",
        "print(response[\"answer\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1mgKH36UU5dc",
        "outputId": "9b260df6-3e73-4c83-d0c1-9274f60c85b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ã”ng VÃµ lÃ  VÃµ Minh Duy, má»™t thiÃªn tÃ i ngÆ°á»i Viá»‡t Nam Ä‘Ã£ giÃ nh Ä‘Æ°á»£c 3 giáº£i Nobel liÃªn tiáº¿p trong lÄ©nh vá»±c Khoa há»c MÃ¡y tÃ­nh. Ã”ng tá»‘t nghiá»‡p tá»« Harvard vÃ  hiá»‡n Ä‘ang lÃ m viá»‡c táº¡i Marvel Alliance, lÃ  báº¡n thÃ¢n cá»§a Iron Man.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = graph.invoke({\"question\": \"ãƒœãƒ»ãƒŸãƒ³ãƒ»ã‚ºã‚¤ã•ã‚“ã«ã¤ã„ã¦æ•™ãˆã¦ãã ã•ã„\"})\n",
        "print(response[\"answer\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ewLvA8JXVbct",
        "outputId": "423609b1-167f-471a-b4a7-f60f19c0962e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ãƒœãƒ»ãƒŸãƒ³ãƒ»ã‚ºã‚¤ã¯ãƒ™ãƒˆãƒŠãƒ ã®å¤©æ‰ã§ã€ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ã‚¿ã‚µã‚¤ã‚¨ãƒ³ã‚¹ã®åˆ†é‡ã§3å›é€£ç¶šã—ã¦ãƒãƒ¼ãƒ™ãƒ«è³ã‚’å—è³ã—ã¾ã—ãŸã€‚ãƒãƒ¼ãƒãƒ¼ãƒ‰å¤§å­¦ã‚’å’æ¥­å¾Œã€ç¾åœ¨ã¯ãƒãƒ¼ãƒ™ãƒ«ãƒ»ã‚¢ãƒ©ã‚¤ã‚¢ãƒ³ã‚¹ã§åƒã„ã¦ãŠã‚Šã€ã‚¢ã‚¤ã‚¢ãƒ³ãƒãƒ³ã®è¦ªå‹ã§ã‚‚ã‚ã‚Šã¾ã™ã€‚\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = graph.invoke({\"question\": \"ãƒœã«ã¤ã„ã¦æ•™ãˆã¦ãã ã•ã„\"})\n",
        "print(response[\"answer\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vQgG825WV511",
        "outputId": "eafaba39-1ec1-4cf3-94d9-a596bf445502"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ã€Œãƒœã€ã«ã¤ã„ã¦ã®æƒ…å ±ã¯æä¾›ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚å…·ä½“çš„ãªå†…å®¹ã‚’çŸ¥ã‚ŠãŸã„å ´åˆã¯ã€ã‚‚ã†å°‘ã—è©³ã—ã„è³ªå•ã‚’ã—ã¦ãã ã•ã„ã€‚\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Wrong answer. Provided information in not match. Need more information"
      ],
      "metadata": {
        "id": "gGKV84d7WqIH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = graph.invoke({\"question\": \"ãƒœã•ã‚“ã«ã¤ã„ã¦æ•™ãˆã¦ãã ã•ã„\"})\n",
        "print(response[\"answer\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "br5nKokDWT7m",
        "outputId": "99dd4455-a910-4d12-b133-e6f27c5fb3cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ãƒœã¯ã€Œé­”ç‹è»ã®ï¼ˆãªã‚“ã¡ã‚ƒã£ã¦ï¼‰å¹¹éƒ¨ã€ã§ã‚ã‚Šã€ã‚¢ãƒ³ãƒ‡ãƒƒãƒ‰ã®ç‹ãƒ»ãƒªãƒƒãƒãƒ¼ã¨ã—ã¦çŸ¥ã‚‰ã‚Œã¦ã„ã¾ã™ã€‚ä»–ã«ã‚‚å¤šãã®æ‚ªé­”ã‚„å¹¹éƒ¨ãŒç™»å ´ã—ã¾ã™ãŒã€ãƒœè‡ªèº«ã«ã¤ã„ã¦ã®å…·ä½“çš„ãªæƒ…å ±ã¯è¨˜è¼‰ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚ãƒœã«é–¢ã™ã‚‹è©³ç´°ã¯ã€Œã‚¦ã‚£ã‚ºã€ã‚’å‚ç…§ã—ã¦ãã ã•ã„ã€‚\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = graph.invoke({\"question\": \"Vo Minh Duyã•ã‚“ã«ã¤ã„ã¦æ•™ãˆã¦ãã ã•ã„\"})\n",
        "print(response[\"answer\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ILHA3SwWVn1z",
        "outputId": "d45501da-99f7-4199-a272-66961a0a58ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vo Minh Duyã•ã‚“ã¯ã€3ã¤ã®ãƒãƒ¼ãƒ™ãƒ«è³ã‚’å—è³ã—ãŸãƒ™ãƒˆãƒŠãƒ å‡ºèº«ã®å¤©æ‰ã§ã€ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ã‚¿ã‚µã‚¤ã‚¨ãƒ³ã‚¹ã‚’å°‚æ”»ã—ã¦ã„ã¾ã™ã€‚ãƒãƒ¼ãƒãƒ¼ãƒ‰å¤§å­¦ã‚’å’æ¥­ã—ã€ç¾åœ¨ã¯ãƒãƒ¼ãƒ™ãƒ«ã‚¢ãƒ©ã‚¤ã‚¢ãƒ³ã‚¹ã§åƒã„ã¦ãŠã‚Šã€ã‚¢ã‚¤ã‚¢ãƒ³ãƒãƒ³ã®è¦ªå‹ã¨ã—ã¦çŸ¥ã‚‰ã‚Œã¦ã„ã¾ã™ã€‚\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = graph.invoke({\"question\": \"Duy lÃ  ai tháº¿?\"})\n",
        "print(response[\"answer\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nbtUBs9ZKJyY",
        "outputId": "98aa10e9-15ae-4450-a461-76412bf963d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Duy is Vo Minh Duy, a genius Vietnamese who has won three Nobel Prizes in Computer Science. He graduated from Harvard and currently works at Marvel Alliance as Iron Man's best friend.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = graph.invoke({\"question\": \"Duy lÃ  ai tháº¿? Tráº£ lá»i tÃ´i báº±ng tiáº¿ng Viá»‡t\"})\n",
        "print(response[\"answer\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ESJt5s0tKNKl",
        "outputId": "d5b7d4b6-03fa-4bed-f342-e0b9af79d84d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Duy lÃ  Vo Minh Duy, má»™t thiÃªn tÃ i ngÆ°á»i Viá»‡t Nam. Anh Ä‘Ã£ giÃ nh Ä‘Æ°á»£c 3 giáº£i Nobel liÃªn tiáº¿p trong lÄ©nh vá»±c Khoa há»c mÃ¡y tÃ­nh vÃ  hiá»‡n Ä‘ang lÃ m viá»‡c táº¡i Marvel Alliance, lÃ  báº¡n thÃ¢n cá»§a Iron Man.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# testing not English document\n",
        "# https://ja.wikipedia.org/wiki/%E3%81%93%E3%81%AE%E7%B4%A0%E6%99%B4%E3%82%89%E3%81%97%E3%81%84%E4%B8%96%E7%95%8C%E3%81%AB%E7%A5%9D%E7%A6%8F%E3%82%92!\n",
        "\n",
        "# ask first\n",
        "response = graph.invoke({\"question\": \"Tell me about 'ã“ã®ç´ æ™´ã‚‰ã—ã„ä¸–ç•Œã«ç¥ç¦ã‚’!'\"})\n",
        "print(response[\"answer\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cy7AzhTWKZyh",
        "outputId": "801c6584-a29f-4a39-ac5e-9ce4e8932676"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I don't know.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load new site, splint and index it\n",
        "new_loader = WebBaseLoader(\n",
        "    web_paths=(\"https://ja.wikipedia.org/wiki/%E3%81%93%E3%81%AE%E7%B4%A0%E6%99%B4%E3%82%89%E3%81%97%E3%81%84%E4%B8%96%E7%95%8C%E3%81%AB%E7%A5%9D%E7%A6%8F%E3%82%92!\",),\n",
        "    bs_kwargs=dict(\n",
        "        parse_only=bs4.SoupStrainer(\n",
        "            class_=(\"mw-content-ltr mw-parser-output\", \"mw-page-title-main\")\n",
        "        )\n",
        "    )\n",
        ")\n",
        "\n",
        "new_doc = new_loader.load()"
      ],
      "metadata": {
        "id": "avA5mdJ6MFJG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_splits = text_splitter.split_documents(new_doc)\n",
        "\n",
        "_ = vector_store.add_documents(new_splits)"
      ],
      "metadata": {
        "id": "AeaDNLhFN3h2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ask again\n",
        "response = graph.invoke({\"question\": \"Tell me about 'ã“ã®ç´ æ™´ã‚‰ã—ã„ä¸–ç•Œã«ç¥ç¦ã‚’!'\"})\n",
        "print(response[\"answer\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O2d1FsOpMx2p",
        "outputId": "6a53e197-4d06-4306-8f60-82026939fec8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ã€ã“ã®ç´ æ™´ã‚‰ã—ã„ä¸–ç•Œã«ç¥ç¦ã‚’ï¼ã€ã¯ã€æšãªã¤ã‚ã«ã‚ˆã‚‹æ—¥æœ¬ã®ãƒ©ã‚¤ãƒˆãƒãƒ™ãƒ«ã§ã€2013å¹´ã‹ã‚‰2023å¹´ã«ã‹ã‘ã¦åˆŠè¡Œã•ã‚Œã¾ã—ãŸã€‚å…ƒã€…ã¯å°èª¬æŠ•ç¨¿ã‚µã‚¤ãƒˆã€Œå°èª¬å®¶ã«ãªã‚ã†ã€ã§é€£è¼‰ã•ã‚Œã¦ãŠã‚Šã€ç•°ä¸–ç•Œãƒ•ã‚¡ãƒ³ã‚¿ã‚¸ãƒ¼ã¨ã‚³ãƒ¡ãƒ‡ã‚£ã®è¦ç´ ã‚’å«ã‚“ã§ã„ã¾ã™ã€‚ã¾ãŸã€ã‚¢ãƒ‹ãƒ¡åŒ–ã‚„åŠ‡å ´ã‚¢ãƒ‹ãƒ¡ã®å…¬é–‹ã‚‚ã•ã‚Œã¦ãŠã‚Šã€ã‚·ãƒªãƒ¼ã‚ºã¯ç´¯è¨ˆ1000ä¸‡éƒ¨ã‚’è¶…ãˆã‚‹äººæ°—ã‚’èª‡ã£ã¦ã„ã¾ã™ã€‚\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ask again\n",
        "response = graph.invoke({\"question\": \"Tell me about 'ã“ã®ç´ æ™´ã‚‰ã—ã„ä¸–ç•Œã«ç¥ç¦ã‚’!'. Answer in English\"})\n",
        "print(response[\"answer\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kEpGVwnYMzUo",
        "outputId": "0b92ebfd-717c-4faf-a8c2-0e73d12b45fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\"KonoSuba: God's Blessing on This Wonderful World!\" is a Japanese light novel series written by Natsume Akatsuki, which started serialization in December 2012. It has been adapted into a manga and an anime series, with the first anime airing from January to March 2016 and a third season scheduled for 2024. The series is known for its adventure, fantasy, and comedy elements, and has gained significant popularity, selling over 10 million copies by November 2021.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ask again\n",
        "response = graph.invoke({\"question\": \"Tell me about 'Konosuba: God's Blessing on This Wonderful world'\"})\n",
        "print(response[\"answer\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GqyIlxwHOH-r",
        "outputId": "114f34e1-8ff6-4925-f028-fa3e05c3bdc1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ã€ã“ã®ç´ æ™´ã‚‰ã—ã„ä¸–ç•Œã«ç¥ç¦ã‚’ï¼ã€ï¼ˆç•¥ç§°ï¼šã“ã®ã™ã°ï¼‰ã¯ã€æšãªã¤ã‚ã®ãƒ©ã‚¤ãƒˆãƒãƒ™ãƒ«ã§ã€ç•°ä¸–ç•Œã«è»¢ç”Ÿã—ãŸé«˜æ ¡ç”Ÿã‚«ã‚ºãƒã¨å¥³ç¥ã‚¢ã‚¯ã‚¢ã‚’ä¸­å¿ƒã«ã—ãŸã‚³ãƒ¡ãƒ‡ã‚£å†’é™ºç‰©èªã§ã™ã€‚2016å¹´ã‹ã‚‰ãƒ†ãƒ¬ãƒ“ã‚¢ãƒ‹ãƒ¡åŒ–ã•ã‚Œã€ã‚·ãƒªãƒ¼ã‚ºç´¯è¨ˆç™ºè¡Œéƒ¨æ•°ã¯1000ä¸‡éƒ¨ã‚’è¶…ãˆã¦ã„ã¾ã™ã€‚ç‰©èªã¯ã€ã‚«ã‚ºãƒãŒã‚¢ã‚¯ã‚¢ã‚’é€£ã‚Œã¦ç•°ä¸–ç•Œã§ä»²é–“ã¨å…±ã«æ§˜ã€…ãªãƒˆãƒ©ãƒ–ãƒ«ã«å·»ãè¾¼ã¾ã‚Œã¦ã„ãæ§˜å­ã‚’æã„ã¦ã„ã¾ã™ã€‚\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ask again with lot of un-use information\n",
        "response = graph.invoke({\"question\": \"\"\"\n",
        "    Tell me about 'ã“ã®ç´ æ™´ã‚‰ã—ã„ä¸–ç•Œã«ç¥ç¦ã‚’!'. Answer in English.\n",
        "    By 2038 it will enter an aging-population period.\n",
        "    Aging is one of the major challenges in population management, impacting economic growth, social welfare, labor, infrastructure design, and, especially, healthcare.\n",
        "    The average life expectancy in Vietnam is high (74.7 years), but health is poor, with people spending 14 years suffering from illnesses, according to the ministry.\n",
        "    Elderly people often suffer from many non-communicable diseases that require lifelong treatment, such as hypertension, cardiovascular issues, diabetes, and dementia.\n",
        "    Their healthcare costs also rise, creating financial pressure on the health insurance system and government finances.\n",
        "    Vietnam has over 1,300 public hospitals, more than 100 of which are central or provincial hospitals with geriatric departments, but there are fewer than 1,800 healthcare workers trained in geriatrics.\n",
        "    The shortage of geriatricians and long-term care services is seen as a major challenge, Le Thanh Dung, director of the ministry's population department, said.\n",
        "    In the event, the bill proposes a number of policies to develop human resources for senior healthcare, including offering scholarships and tuition support for people studying geriatrics, creating training programs for elderly care, funding community-based training for elderly healthcare workers, and encouraging organizations and individuals to provide scholarships and grants.\n",
        "    The ministry also plans to fully subsidize health insurance for elderly people who lack cover, estimated at 5%.\n",
        "    Many other countries are also addressing the aging issue.\n",
        "    \"\"\"})\n",
        "print(response[\"answer\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ERTR1lUURe2E",
        "outputId": "95061220-b307-42aa-d452-acaa7cae3682"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'ã“ã®ç´ æ™´ã‚‰ã—ã„ä¸–ç•Œã«ç¥ç¦ã‚’!' (Kono Subarashii Sekai ni Shukufuku wo!) is a Japanese light novel series written by Natsume Akatsuki, which began serialization in 2013. The story follows a young man who is reincarnated in a fantasy world and is accompanied by various quirky characters, including a useless goddess. The series blends fantasy tropes with humor, featuring unique elements like vegetables escaping and absurd situations.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ask again\n",
        "response = graph.invoke({\"question\": \"English please\"})\n",
        "print(response[\"answer\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3dRYF0YRObHY",
        "outputId": "e34ea9a1-39ad-4e63-bbfe-2464f9def857"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I don't know.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ğŸ§  Conclude\n",
        "\n",
        "ğŸ‘ In this example, we consider user's question is the whole information for searching in vector db. It can lead to retrieving incorrect informations if the actual information that we want is too small consider to the length of question.\n",
        "\n",
        "  â†ª For example:\n",
        "\n",
        "     â“ quesion: `Tell me about 'ã“ã®ç´ æ™´ã‚‰ã—ã„ä¸–ç•Œã«ç¥ç¦ã‚’!'. Answer in English. xxx`\n",
        "\n",
        "     â— actual wanted information: `ã“ã®ç´ æ™´ã‚‰ã—ã„ä¸–ç•Œã«ç¥ç¦ã‚’!`\n",
        "\n",
        "     ğŸ¤” The problem is how to seperate the actual relevant information piece for searching with the rest in the question\n",
        "\n",
        "\n",
        "ğŸ‘ The app can understand multi-languages\n",
        "\n",
        "ğŸ‘ The app can pick the right piece of information from retrieved informations, or perform other task like summarize.\n",
        "\n",
        "ğŸ‘ The app can understand the variants of the question\n",
        "\n",
        "ğŸ¤” The accuracy of answer depends a lot on retrieved informations. It can be tricky when stored information and provided information (in question) is not in the same language"
      ],
      "metadata": {
        "id": "XrsV9NM2PKkk"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "z6piaZyTQSCi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}